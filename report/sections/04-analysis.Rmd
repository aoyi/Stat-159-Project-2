
# Analysis

## Exploratory Data Analysis (EDA)

The first step of conducting analysis is to understand the data by conducting exploratory data analysis. To conduct the EDA, we obtained descriptive statistics and summaries of all variables by using the R package "FactoMineR". For the quantitative variables, we wrote a function called output_quantitative_stats() to get minimum, maximum, range, median, first and third quartiles, IQR, Mean and Sd of all the quantitative variables including "Income", "Limit", "Rating", "Cards", "Age", "Education", and "Balance". Similarly, we wrote a function called output_qualitative_stats() to generate a table with both the frequency and the relative frequency of the qualitative variables including "Gender", "Student", "Married", and "Ethnicity". To understand the data better, we also want to generate some plots to visualize the data. We wrote the functions histogram_generator() and boxplot_generator() to generate histograms and boxplots of the quantitative variables and condition_boxplot_generator() to generate conditional boxplots between "Balance" and the qualitative variables. To study the association between "Balance" and the rest of predictors, we also obtained the correlation matrix of all quantitative variables using function cor(), the scatterplot matrix using function pairs(), the anova between "Balance" and all the qualitaive variables using function aov(), and the PCA plot for the quantitative variables using function PCA().

## Pre-modeling Data Processing

The second step before conducting analysis is to process the raw data into the data to be used in the further analysis. We used function model.matrix() to transform each categorical variable into dummy variables and function scale() to mean-center and standardize the data. We saved the processed data as scaled-credit.csv and we used the processed data for the model building process. 

## Regression Models

The third step is to build and evaluate a model on the processed data of size 400. We used sample() function to get a training set of size 300 to build the model and a test set of size 100 to assess the performance. For reproducibility purpose, we used function set.seed() before taking the sample. 

After getting the training set and test set, we fitted a multiple linear regression model via Ordinary Least Squares (OLS) using the lm() function and set this as a benchmark. In addition to the OLS model, we used other four regression methods including Ridge regression (RR), Lasso regression (LR), Principal Components regression (PCR) and Partial Least Squares regression (PLSR) to fit the data set. To cooperate on the model building process and to make the workflow reproducible and efficient, we created a new feature branch for each of the four regression approaches. Each team member worked on different regression models on different branches and then merged them into the master branch. We have four feature branches named 'ridge', 'lasso', 'pcr' and 'plsr' and each member contributed to two branches. 

For ridge regression method and lasso regression method, we used R package "glmnet" and we used cv.glmnet() function to conduct ten-fold cross-validation on the train set. When we applied the cv.glmnet() function, we set alpha = 0 for ridge regression and alpha = 1 for lasso regression and we set intercept = FALSE and standardize = FALSE for both regressions since we already mean-centered and standardized all the variables. After conducting ten-fold cross-validation on the train set, we got the best lambda, which is the smallest lambda for each regression. We then used the best fitted lambda on the test set using function predict() and calculated the test MSE. We will use the test MSE to compare the performance of all the models later. Last, we used function glmnet() to refit the model on the full data set using the best lambda chosen by cross-validation and got the "official" coefficient estimates by function coef().

For pcr regression method and plsr regression method, we used R package "pls". We used function pcr() with the argument validation = "CV" to perform 10-fold cross-validation for pcr regression and we used function plsr() with the argument validation = "CV" to perform 10-fold cross-validation for plsr regression. After conducting cross-validation on the train set, we got the best m that minimizes the validation error and we plotted the cross-validation errors using the function validationplot() with argument val.type = "MSEP". We then used the best fitted m on the test set using function predict() and calculated the test MSE. Finally, we used function pcr() and plsr() for each regression method to refit the model on the full data set using the best m chosen by cross-validation and got the coefficient estimates. 

After we finished the model building process, we saved all the outputs and graphs for further comparison and analysis and merged the feature branches with the "master" branch. To compare five regression methods and choose the best one, we used R packages "Matrix" and "xtable" to get a table of regression coefficients for all five methods with each column per regression method. We also included another table with the test MSE values for all regression methods. To visualize and compare the coefficients, we generated a plot of trend lines of the coefficients of five regression methods. 



